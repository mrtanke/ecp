{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a0f30f8b-5be6-4e07-8c37-475114f06c3a",
      "metadata": {
        "id": "a0f30f8b-5be6-4e07-8c37-475114f06c3a"
      },
      "source": [
        "# Lab 02: Manual Full-Integer Post-Training Quantization (PTQ) using a LeNet-Inspired CNN\n",
        "\n",
        "## Overview\n",
        "In this lab, you will explore how to apply **manual full-integer post-training quantization (PTQ)** to a pre-trained convolutional neural network (CNN).  \n",
        "You will start with a **pre-trained LeNet-inspired model** trained on the MNIST dataset in full precision (FP32), evaluate its accuracy, and then apply **manual dynamic scaling functions** after each layer to simulate quantization to 8-bit integers.  \n",
        "Finally, you will compare the accuracy of the quantized model to the original FP32 model and discuss how different integer bit-widths affect performance.\n",
        "\n",
        "## Learning Objectives\n",
        "By the end of this lab, you will be able to:\n",
        "1. Get familiar with **full-integer post-training quantization (PTQ)** and apply it manually to a custom CNN.\n",
        "2. Understand the **impact of different integer bit-widths** on network accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d458ef7-6ed8-42c5-bab0-bc6b6aca1121",
      "metadata": {
        "id": "3d458ef7-6ed8-42c5-bab0-bc6b6aca1121"
      },
      "source": [
        "## Step 1: Import Required Libraries\n",
        "\n",
        "In this step, we import essential libraries for building and training our CNN model.  \n",
        "TensorFlow and Keras are used for model design and training, while NumPy and Matplotlib help with numerical operations and visualization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d3db5f80-9846-4567-9698-9d8517ba9aad",
      "metadata": {
        "id": "d3db5f80-9846-4567-9698-9d8517ba9aad"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12335ee1-2ae3-463b-93a0-0285390af1b6",
      "metadata": {
        "id": "12335ee1-2ae3-463b-93a0-0285390af1b6"
      },
      "source": [
        "## Step 2: Load the MNIST Dataset\n",
        "\n",
        "The **MNIST dataset** (Modified National Institute of Standards and Technology) is a widely used benchmark dataset in the field of machine learning and computer vision. It consists of 70,000 grayscale images of handwritten digits (0 to 9), each measuring 28x28 pixels. The dataset is divided into train set and test set, making it an ideal resource for training and evaluating machine learning models.\n",
        "\n",
        "**Training Images**: The training set consists of 60,000 images used to train the model. It allows the model to learn the features of the digits.\n",
        "\n",
        "**Testing Images**: The testing set includes 10,000 images used to evaluate the model's performance after training. This helps assess how well the model can generalize to unseen data.\n",
        "\n",
        "The pixel values of the images range from 0 to 255, where:\n",
        "\n",
        "0 represents black (no intensity),\n",
        "255 represents white (maximum intensity),\n",
        "Values in between represent varying shades of gray."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0f1f53c9-0fdf-4dcc-a0e0-69b0f24b0d7d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "0f1f53c9-0fdf-4dcc-a0e0-69b0f24b0d7d",
        "outputId": "02641090-b93a-4784-d968-76f7ee670eed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x300 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (60000, 28, 28, 1) (60000,)\n",
            "Test data shape: (10000, 28, 28, 1) (10000,)\n"
          ]
        }
      ],
      "source": [
        "# -------------------------\n",
        "# 1) Data: load + preprocess\n",
        "# -------------------------\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# MNIST is 28x28 grayscale.\n",
        "x_train = x_train.astype(\"float32\")\n",
        "x_test  = x_test.astype(\"float32\")\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test  = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "x_test_fp = x_test\n",
        "\n",
        "#To visualize three test images from the testing set along with their corresponding labels, you can use the following code:\n",
        "# Define the number of images to display\n",
        "num_images = 5\n",
        "\n",
        "# Create subplots for each image\n",
        "plt.figure(figsize=(10, 3))\n",
        "for i in range(num_images):\n",
        "    plt.subplot(1, num_images, i + 1)\n",
        "    plt.imshow(x_test[i], cmap='gray')\n",
        "    plt.title(f\"Label: {y_test[i]}\")\n",
        "    plt.axis('off')  # Hide the axis\n",
        "\n",
        "# Automatically adjusts spacing between subplots so titles and images don’t overlap.\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Check the shape of the data\n",
        "print(\"Training data shape:\", x_train.shape, y_train.shape)\n",
        "print(\"Test data shape:\", x_test.shape, y_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3efec178-8848-4cd3-8150-8b3713a45283",
      "metadata": {
        "id": "3efec178-8848-4cd3-8150-8b3713a45283"
      },
      "source": [
        "## Step 3: Load Pre-trained FP32 Model\n",
        "\n",
        "Here, we load a **pre-trained LeNet-Inspired CNN model** trained earlier in full precision (FP32).  \n",
        "Make sure the file path points to your saved model file, `lenet_inspired_fp32_full.keras`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6f42a3e3-0b55-4efe-a5a6-b2466c3c480e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "6f42a3e3-0b55-4efe-a5a6-b2466c3c480e",
        "outputId": "91b7812e-ccc8-4481-c3a5-b8ef1e5fad24"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"LeNet5_Inspired_Dynamic_FloatSim\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"LeNet5_Inspired_Dynamic_FloatSim\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu (\u001b[38;5;33mReLU\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_1 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m528\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_2 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │         \u001b[38;5;34m1,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_3 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m4\u001b[0m)      │           \u001b[38;5;34m292\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_4 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m4\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m295,040\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_5 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_6 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">292</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m308,134\u001b[0m (1.18 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">308,134</span> (1.18 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m308,134\u001b[0m (1.18 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">308,134</span> (1.18 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Load your trained FP32 model\n",
        "fp32_model = load_model(\"lenet_inspired_fp32_full.keras\", compile=False)\n",
        "fp32_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0cfb3e0-85b1-4574-80fd-97de0b9c44a0",
      "metadata": {
        "id": "c0cfb3e0-85b1-4574-80fd-97de0b9c44a0"
      },
      "source": [
        "## Step 4: Evaluate FP32 Model Accuracy\n",
        "\n",
        "Before quantization, evaluate the full-precision model on the MNIST test dataset.  \n",
        "This will serve as the **baseline accuracy** for comparison after quantization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "123bbfff-d58d-48f8-88bd-dc3b9167a955",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "123bbfff-d58d-48f8-88bd-dc3b9167a955",
        "outputId": "f1e538c7-8199-4e80-bc1c-d53610835dc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step\n",
            "Accuracy of FP32 pre-traind model on full MNIST test set: 0.9870\n"
          ]
        }
      ],
      "source": [
        "# Forward pass on full test set\n",
        "logits = fp32_model.predict(x_test_fp, batch_size=64)  # verbose=2 shows progress bar\n",
        "preds = np.argmax(logits, axis=1)\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = np.mean(preds == y_test)\n",
        "print(f\"Accuracy of FP32 pre-traind model on full MNIST test set: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07a27107-f603-4a29-9558-2e6c00ecbc2b",
      "metadata": {
        "id": "07a27107-f603-4a29-9558-2e6c00ecbc2b"
      },
      "source": [
        "## Step 5: Define Dynamic Rescaling Function\n",
        "\n",
        "We define a function that normalizes, scales, and quantizes tensors to simulate 8-bit integer quantization.  \n",
        "This function rescales data dynamically based on its maximum absolute value.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "68182f70-6b15-4b58-9a7b-8263fc5aa55f",
      "metadata": {
        "id": "68182f70-6b15-4b58-9a7b-8263fc5aa55f"
      },
      "outputs": [],
      "source": [
        "def dynamic_rescale_float_tensor(x):\n",
        "    # Find per-tensor absolute max\n",
        "    max_abs = tf.reduce_max(tf.abs(x))\n",
        "    # Scale into [-1, 1], then multiply to match int8 range -> The int8 range is roughly [-128, 127]\n",
        "    x_norm = x / max_abs\n",
        "    x_scaled = tf.round(x_norm * 127.0)\n",
        "    x_clipped = tf.clip_by_value(x_scaled, -127.0, 127.0) # -> Ensures values stay strictly within [-127, 127]\n",
        "\n",
        "    # The values now represent int8 numbers, but stored as float32, simulating quantized behavior.\n",
        "    return tf.cast(x_clipped, tf.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "337026a0-d310-452c-b871-32309ecc2d97",
      "metadata": {
        "id": "337026a0-d310-452c-b871-32309ecc2d97"
      },
      "source": [
        "## Step 6: Build Quantization Simulation Model\n",
        "\n",
        "We create a new model with the same structure as the FP32 model.  \n",
        "Then, it will receive quantized weights and quantized input data in the next steps to simulate integer-only inference.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ce6dcf91-599d-4324-b1a8-b86784901447",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 958
        },
        "id": "ce6dcf91-599d-4324-b1a8-b86784901447",
        "outputId": "bf6acbb3-b4b7-4d11-8b9e-39a44b4506ba"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"LeNet_Dynamic_quantization\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"LeNet_Dynamic_quantization\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu (\u001b[38;5;33mReLU\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lambda (\u001b[38;5;33mLambda\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_1 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lambda_1 (\u001b[38;5;33mLambda\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m528\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_2 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lambda_2 (\u001b[38;5;33mLambda\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │         \u001b[38;5;34m1,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_3 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lambda_3 (\u001b[38;5;33mLambda\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m8\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m4\u001b[0m)      │           \u001b[38;5;34m292\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_4 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m4\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lambda_4 (\u001b[38;5;33mLambda\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m4\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m295,040\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_5 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lambda_5 (\u001b[38;5;33mLambda\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_6 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lambda_6 (\u001b[38;5;33mLambda\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lambda_7 (\u001b[38;5;33mLambda\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lambda_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lambda_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lambda_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">292</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lambda_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lambda_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lambda_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lambda_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m308,134\u001b[0m (1.18 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">308,134</span> (1.18 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m308,134\u001b[0m (1.18 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">308,134</span> (1.18 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ------------------------------\n",
        "# Build Functional Model\n",
        "# ------------------------------\n",
        "def build_lenet_dynamic_float_sim():\n",
        "    inp = layers.Input(shape=(28, 28, 1))\n",
        "\n",
        "    # Conv 1\n",
        "    x = layers.Conv2D(64, (1,1), activation=None, padding=\"valid\")(inp)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.Lambda(dynamic_rescale_float_tensor)(x)  # Simulate int8 scaling\n",
        "\n",
        "    # Conv 2\n",
        "    x = layers.Conv2D(32, (1,1), activation=None, padding=\"valid\")(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.Lambda(dynamic_rescale_float_tensor)(x)\n",
        "\n",
        "    # Conv 3\n",
        "    x = layers.Conv2D(16, (1,1), activation=None, padding=\"valid\")(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.Lambda(dynamic_rescale_float_tensor)(x)\n",
        "\n",
        "    # Conv 4 (3×3)\n",
        "    x = layers.Conv2D(8, (3,3), activation=None, padding=\"valid\")(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.Lambda(dynamic_rescale_float_tensor)(x)\n",
        "\n",
        "    # Conv 5 (3×3)\n",
        "    x = layers.Conv2D(4, (3,3), activation=None, padding=\"valid\")(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.Lambda(dynamic_rescale_float_tensor)(x)\n",
        "\n",
        "    # Flatten\n",
        "    x = layers.Flatten()(x)\n",
        "\n",
        "    # Dense 1\n",
        "    x = layers.Dense(128, activation=None)(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.Lambda(dynamic_rescale_float_tensor)(x)\n",
        "\n",
        "    # Dense 2\n",
        "    x = layers.Dense(64, activation=None)(x)\n",
        "    x = layers.ReLU()(x)\n",
        "    x = layers.Lambda(dynamic_rescale_float_tensor)(x)\n",
        "\n",
        "    # Final Dense (no activation, raw logits)\n",
        "    x = layers.Dense(10, activation=None)(x)\n",
        "    x = layers.Lambda(dynamic_rescale_float_tensor)(x)  # ✅ Final scale simulation\n",
        "\n",
        "    model = Model(inputs=inp, outputs=x, name=\"LeNet_Dynamic_quantization\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# ------------------------------\n",
        "# Build and inspect\n",
        "# ------------------------------\n",
        "quantized_model = build_lenet_dynamic_float_sim()\n",
        "quantized_model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "409ec35e-e68d-4837-a697-469a215a4f77",
      "metadata": {
        "id": "409ec35e-e68d-4837-a697-469a215a4f77"
      },
      "source": [
        "## Step 7: Quantizing Pre-trained FP32 Weights\n",
        "\n",
        "In this step, we take the weights and biases from each convolutional and dense layer in the FP32 model,  \n",
        "apply our dynamic rescaling function to them, and then assign the quantized versions to the new simulation model.  \n",
        "This simulates quantized **integer weights** stored as float32.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d0fb24c3-8244-4dfa-8577-12c07631a062",
      "metadata": {
        "id": "d0fb24c3-8244-4dfa-8577-12c07631a062"
      },
      "outputs": [],
      "source": [
        "#------------------------------\n",
        "# Extract Conv2D and Dense layers for quantization\n",
        "#------------------------------\n",
        "# Collect Conv/Dense layers in float_sim_model\n",
        "quantized_layers = [l for l in quantized_model.layers if isinstance(l, layers.Conv2D) or isinstance(l, layers.Dense)]\n",
        "fp32_layers = [l for l in fp32_model.layers if isinstance(l, layers.Conv2D) or isinstance(l, layers.Dense)]\n",
        "\n",
        "# Transfer quantized weights\n",
        "for q_l, fp32_l in zip(quantized_layers, fp32_layers):\n",
        "    w, b = fp32_l.get_weights()\n",
        "    w_q = dynamic_rescale_float_tensor(w)\n",
        "    b_q = dynamic_rescale_float_tensor(b)\n",
        "    q_l.set_weights([w_q, b_q])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32080eae-1384-454b-9cd0-1f656152df5d",
      "metadata": {
        "id": "32080eae-1384-454b-9cd0-1f656152df5d"
      },
      "source": [
        "## Step 8: Quantizing the MNIST Dataset\n",
        "\n",
        "Here, we quantize the **input activations** (test images) using the same scaling principle.  \n",
        "This simulates integer-only input data, which allows the entire inference pipeline to behave as if it were using int8 arithmetic.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0bfa0923-29f2-45d8-8ff2-83bd238e3971",
      "metadata": {
        "id": "0bfa0923-29f2-45d8-8ff2-83bd238e3971"
      },
      "outputs": [],
      "source": [
        "# 1. Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# 2️. Convert to float32 for safe division\n",
        "x_test = tf.cast(x_test, tf.float32)\n",
        "\n",
        "# 3️. Normalize pixel values from [0, 255] → [0, 1]\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# 4️. Scale normalized values from [0, 1] → [0, 127]\n",
        "x_test = x_test * 127.0\n",
        "\n",
        "# 5️. Round to nearest integer\n",
        "x_test = tf.round(x_test)\n",
        "\n",
        "# 6️. Clip to make sure everything is within [0, 127]\n",
        "x_test = tf.clip_by_value(x_test, 0.0, 127.0)\n",
        "\n",
        "# 7. Reshape to (num_samples, 28, 28, 1)\n",
        "x_test = tf.reshape(x_test, (-1, 28, 28, 1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26ec93b5-4654-4c04-89cd-24a6124153f5",
      "metadata": {
        "id": "26ec93b5-4654-4c04-89cd-24a6124153f5"
      },
      "source": [
        "## Step 7: Evaluate Quantized Simulation Model\n",
        "\n",
        "Now we evaluate the quantized simulation model to observe the effect of integer quantization on accuracy.  \n",
        "Compare this accuracy to the FP32 baseline to understand quantization loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f4f1da1c-e525-4b1f-ad9b-50e9c91fc797",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4f1da1c-e525-4b1f-ad9b-50e9c91fc797",
        "outputId": "a354bf04-ee20-4203-ec6a-459dd5b6101c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 46ms/step\n",
            "Accuracy of quantized model on full MNIST test set: 0.9868\n"
          ]
        }
      ],
      "source": [
        "# Forward pass on full test set\n",
        "logits = quantized_model.predict(x_test, batch_size=64)  # verbose=2 shows progress bar\n",
        "preds = np.argmax(logits, axis=1)\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = np.mean(preds == y_test)\n",
        "print(f\"Accuracy of quantized model on full MNIST test set: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48af261c-8571-4b32-b3b9-533bac3ad524",
      "metadata": {
        "id": "48af261c-8571-4b32-b3b9-533bac3ad524"
      },
      "source": [
        "## Step 8: Exercise – Quantization with Smaller Integer Bit-Widths\n",
        "\n",
        "Now that you have successfully performed **full-integer post-training quantization (PTQ)** with 8-bit integers, your task is to **repeat the same quantization process** using smaller integer representations — **from 7-bit down to 4-bit**.\n",
        "Record the accuracy for each bit-width (7, 6, 5, and 4) and compare them to the 8-bit result.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 8.1: Define Dynamic Rescaling Function"
      ],
      "metadata": {
        "id": "dS7iIy_K0RVS"
      },
      "id": "dS7iIy_K0RVS"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Dynamic Rescaling Function\n",
        "def dynamic_rescale_float_tensor(x, bit_width):\n",
        "    # Find per-tensor absolute max (avoid division by zero)\n",
        "    max_abs = tf.reduce_max(tf.abs(x))\n",
        "\n",
        "    # Normalize to [-1, 1]\n",
        "    x_norm = x / max_abs\n",
        "\n",
        "    # Compute quantization limits\n",
        "    qmax = float(2 ** (bit_width - 1) - 1)\n",
        "    qmin = -qmax\n",
        "\n",
        "    # Scale, round, and clip to int range\n",
        "    x_scaled = tf.round(x_norm * qmax)\n",
        "    x_clipped = tf.clip_by_value(x_scaled, qmin, qmax)\n",
        "\n",
        "    # Return float32 tensor representing quantized values\n",
        "    return tf.cast(x_clipped, tf.float32)"
      ],
      "metadata": {
        "id": "cxF4iSoDdvqi"
      },
      "id": "cxF4iSoDdvqi",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 8.2: Build Quantization Simulation Model"
      ],
      "metadata": {
        "id": "DJcRE5Oj0kYw"
      },
      "id": "DJcRE5Oj0kYw"
    },
    {
      "cell_type": "code",
      "source": [
        "def build_lenet_dynamic_float_sim(bit_width):\n",
        "  inp = layers.Input(shape=(28, 28, 1))\n",
        "\n",
        "  # Conv 1\n",
        "  x = layers.Conv2D(64, (1,1), activation=None, padding=\"valid\")(inp)\n",
        "  x = layers.ReLU()(x)\n",
        "  x = layers.Lambda(dynamic_rescale_float_tensor, arguments={'bit_width': bit_width})(x)  # Simulate int8 scaling\n",
        "\n",
        "  # Conv 2\n",
        "  x = layers.Conv2D(32, (1,1), activation=None, padding=\"valid\")(x)\n",
        "  x = layers.ReLU()(x)\n",
        "  x = layers.Lambda(dynamic_rescale_float_tensor, arguments={'bit_width': bit_width})(x)\n",
        "\n",
        "  # Conv 3\n",
        "  x = layers.Conv2D(16, (1,1), activation=None, padding=\"valid\")(x)\n",
        "  x = layers.ReLU()(x)\n",
        "  x = layers.Lambda(dynamic_rescale_float_tensor, arguments={'bit_width': bit_width})(x)\n",
        "\n",
        "  # Conv 4 (3×3)\n",
        "  x = layers.Conv2D(8, (3,3), activation=None, padding=\"valid\")(x)\n",
        "  x = layers.ReLU()(x)\n",
        "  x = layers.Lambda(dynamic_rescale_float_tensor, arguments={'bit_width': bit_width})(x)\n",
        "\n",
        "  # Conv 5 (3×3)\n",
        "  x = layers.Conv2D(4, (3,3), activation=None, padding=\"valid\")(x)\n",
        "  x = layers.ReLU()(x)\n",
        "  x = layers.Lambda(dynamic_rescale_float_tensor, arguments={'bit_width': bit_width})(x)\n",
        "\n",
        "  # Flatten\n",
        "  x = layers.Flatten()(x)\n",
        "\n",
        "  # Dense 1\n",
        "  x = layers.Dense(128, activation=None)(x)\n",
        "  x = layers.ReLU()(x)\n",
        "  x = layers.Lambda(dynamic_rescale_float_tensor, arguments={'bit_width': bit_width})(x)\n",
        "\n",
        "  # Dense 2\n",
        "  x = layers.Dense(64, activation=None)(x)\n",
        "  x = layers.ReLU()(x)\n",
        "  x = layers.Lambda(dynamic_rescale_float_tensor, arguments={'bit_width': bit_width})(x)\n",
        "\n",
        "  # Final Dense (no activation, raw logits)\n",
        "  x = layers.Dense(10, activation=None)(x)\n",
        "  x = layers.Lambda(dynamic_rescale_float_tensor, arguments={'bit_width': bit_width})(x)  # ✅ Final scale simulation\n",
        "\n",
        "  model = Model(inputs=inp, outputs=x, name=\"LeNet_Dynamic_quantization\")\n",
        "\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "yPy7XOO9emWS"
      },
      "id": "yPy7XOO9emWS",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 8.3\n",
        "1. Quantizing Pre-trained FP32 Weights\n",
        "2. Quantizing the MNIST Dataset\n",
        "3. Evaluate Quantized Simulation Model"
      ],
      "metadata": {
        "id": "8oPYH3n-1DFE"
      },
      "id": "8oPYH3n-1DFE"
    },
    {
      "cell_type": "code",
      "source": [
        "# For bit-width 7, 6, 5, 4\n",
        "bit_widths = [7, 6, 5, 4]\n",
        "\n",
        "for bit_width in bit_widths:\n",
        "  quantized_model = build_lenet_dynamic_float_sim(bit_width)\n",
        "\n",
        "  # Quantizing Pre-trained FP32 Weights\n",
        "  quantized_layers = [l for l in quantized_model.layers if isinstance(l, layers.Conv2D) or isinstance(l, layers.Dense)]\n",
        "  fp32_layers = [l for l in fp32_model.layers if isinstance(l, layers.Conv2D) or isinstance(l, layers.Dense)]\n",
        "\n",
        "  # Transfer quantized weights\n",
        "  for q_l, fp32_l in zip(quantized_layers, fp32_layers):\n",
        "      w, b = fp32_l.get_weights()\n",
        "      w_q = dynamic_rescale_float_tensor(w, bit_width)\n",
        "      b_q = dynamic_rescale_float_tensor(b, bit_width)\n",
        "      q_l.set_weights([w_q, b_q])\n",
        "\n",
        "  # Quantizing the MNIST Dataset\n",
        "  qmax = float(2 ** (bit_width - 1) - 1)\n",
        "  (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "  x_test = tf.cast(x_test, tf.float32)\n",
        "  x_test = x_test / 255.0\n",
        "  x_test = x_test * qmax\n",
        "  x_test = tf.round(x_test)\n",
        "\n",
        "  x_test = tf.clip_by_value(x_test, 0.0, qmax)\n",
        "\n",
        "  x_test = tf.reshape(x_test, (-1, 28, 28, 1))\n",
        "\n",
        "  # Evaluate Quantized Simulation Model\n",
        "  logits = quantized_model.predict(x_test, batch_size=64)\n",
        "  preds = np.argmax(logits, axis=1)\n",
        "\n",
        "  accuracy = np.mean(preds == y_test)\n",
        "  print(f\"Accuracy of quantized model (bit_width = {bit_width}) on full MNIST test set: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azIc-K2hYVTq",
        "outputId": "1a46aa7e-0dbb-4f29-e7d9-c88bcc11b726"
      },
      "id": "azIc-K2hYVTq",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step\n",
            "Accuracy of quantized model (bit_width = 7) on full MNIST test set: 0.9859\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step\n",
            "Accuracy of quantized model (bit_width = 6) on full MNIST test set: 0.9865\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 46ms/step\n",
            "Accuracy of quantized model (bit_width = 5) on full MNIST test set: 0.9821\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step\n",
            "Accuracy of quantized model (bit_width = 4) on full MNIST test set: 0.7847\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}